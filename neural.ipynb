{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup üèóÔ∏è\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "viscos = 1/5200\n",
    "\n",
    "# load RANS data created by rans.m (which can be downloaded)\n",
    "# load DNS data\n",
    "DNS_mean  = np.genfromtxt(\"LM_Channel_5200_mean_prof.dat\",comments=\"%\").transpose()\n",
    "y_DNS     = DNS_mean[0]\n",
    "yplus_DNS = DNS_mean[1]\n",
    "u_DNS     = DNS_mean[2]\n",
    "dudy_DNS  = np.gradient(u_DNS,y_DNS)\n",
    "\n",
    "DNS_stress = np.genfromtxt(\"LM_Channel_5200_vel_fluc_prof.dat\",comments=\"%\").transpose()\n",
    "\n",
    "uu_DNS = DNS_stress[2]\n",
    "vv_DNS = DNS_stress[3]\n",
    "ww_DNS = DNS_stress[4]\n",
    "uv_DNS = DNS_stress[5]\n",
    "uw_DNS = DNS_stress[6]\n",
    "vw_DNS = DNS_stress[7]\n",
    "k_DNS  = 0.5*(uu_DNS+vv_DNS+ww_DNS)\n",
    "\n",
    "DNS_RSTE = np.genfromtxt(\"LM_Channel_5200_RSTE_k_prof.dat\",comments=\"%\")\n",
    "\n",
    "eps_DNS = DNS_RSTE[:,7]/viscos # it is scaled with ustar**4/viscos\n",
    "\n",
    "# fix wall\n",
    "eps_DNS[0]=eps_DNS[1]\n",
    "\n",
    "# load data from k-omega RANS\n",
    "data  = np.loadtxt('y_u_k_om_uv_5200-RANS-code.txt').transpose()\n",
    "y     = data[0]\n",
    "u     = data[1]\n",
    "k     = data[2]\n",
    "om    = data[3]\n",
    "diss1 = 0.09*k*om\n",
    "ustar = (viscos*u[0]/y[0])**0.5\n",
    "yplus = y*ustar/viscos\n",
    "\n",
    "# dont train on, uu, vv, ww, uv, uw, vw \n",
    "# Maybe mixed terms are ok (just not uu,vv,ww)\n",
    "\n",
    "#-----------------Data_manipulation--------------------\n",
    "\n",
    "# Delete first value for all interesting data\n",
    "uv_DNS    = np.delete(uv_DNS, 0)\n",
    "vv_DNS    = np.delete(vv_DNS, 0)\n",
    "ww_DNS    = np.delete(ww_DNS, 0)\n",
    "uw_DNS    = np.delete(uw_DNS,0)\n",
    "vw_DNS    = np.delete(vw_DNS,0)\n",
    "k_DNS     = np.delete(k_DNS, 0)\n",
    "eps_DNS   = np.delete(eps_DNS, 0)\n",
    "dudy_DNS  = np.delete(dudy_DNS, 0)\n",
    "yplus_DNS = np.delete(yplus_DNS,0)\n",
    "uu_DNS    = np.delete(uu_DNS,0)\n",
    "y_DNS     = np.delete(y_DNS,0)\n",
    "u_DNS     = np.delete(u_DNS,0)\n",
    "\n",
    "# Calculate ny_t and time-scale tau\n",
    "viscous_t = k_DNS**2/eps_DNS \n",
    "tau       = viscous_t/abs(uv_DNS)\n",
    "\n",
    "# Calculate c_1, c_2, & c_3 of the Non-linear Eddy Viscosity Model\n",
    "# Array for storing c_1, c_2, & c_3\n",
    "c_0 = -2*(ww_DNS/k_DNS - 2/3)/(tau**2*dudy_DNS**2)\n",
    "c_2 = 2*((ww_DNS/k_DNS - 2/3) + (uu_DNS/k_DNS - 2/3))/(tau**2*dudy_DNS**2)\n",
    "\n",
    "#TODO ML using PyTorch to estimate c_1, c_2, & c_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[2].dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up input and output as tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack several arrays horizontally to create a feature matrix\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = StandardScaler()\n",
    "\n",
    "X = np.column_stack((y_DNS, yplus_DNS, u_DNS, dudy_DNS, k_DNS))\n",
    "\n",
    "# transpose the target vector to make it a column vector\n",
    "y = c.transpose()\n",
    "\n",
    "# split the feature matrix and target vector into training and validation sets\n",
    "# test_size=0.2 means we reserve 20% of the data for validation\n",
    "# random_state=42 is a fixed seed for the random number generator, ensuring reproducibility\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_scaled = scaler1.fit_transform(X_train)\n",
    "X_val_scaled   = scaler2.fit_transform(X_val)\n",
    "\n",
    "\n",
    "# convert the numpy arrays to PyTorch tensors with float32 data type\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# create PyTorch datasets and dataloaders for the training and validation sets\n",
    "# a TensorDataset wraps the feature and target tensors into a single dataset\n",
    "# a DataLoader loads the data in batches and shuffles the batches if shuffle=True\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up a neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.011\n",
      "[1,    20] loss: 0.011\n",
      "[2,    10] loss: 0.008\n",
      "[2,    20] loss: 0.007\n",
      "[3,    10] loss: 0.006\n",
      "[3,    20] loss: 0.005\n",
      "[4,    10] loss: 0.005\n",
      "[4,    20] loss: 0.004\n",
      "[5,    10] loss: 0.003\n",
      "[5,    20] loss: 0.003\n",
      "[6,    10] loss: 0.003\n",
      "[6,    20] loss: 0.003\n",
      "[7,    10] loss: 0.002\n",
      "[7,    20] loss: 0.002\n",
      "[8,    10] loss: 0.002\n",
      "[8,    20] loss: 0.002\n",
      "[9,    10] loss: 0.002\n",
      "[9,    20] loss: 0.002\n",
      "[10,    10] loss: 0.002\n",
      "[10,    20] loss: 0.002\n",
      "[11,    10] loss: 0.002\n",
      "[11,    20] loss: 0.002\n",
      "[12,    10] loss: 0.002\n",
      "[12,    20] loss: 0.001\n",
      "[13,    10] loss: 0.001\n",
      "[13,    20] loss: 0.002\n",
      "[14,    10] loss: 0.001\n",
      "[14,    20] loss: 0.001\n",
      "[15,    10] loss: 0.001\n",
      "[15,    20] loss: 0.001\n",
      "[16,    10] loss: 0.001\n",
      "[16,    20] loss: 0.001\n",
      "[17,    10] loss: 0.001\n",
      "[17,    20] loss: 0.001\n",
      "[18,    10] loss: 0.001\n",
      "[18,    20] loss: 0.001\n",
      "[19,    10] loss: 0.001\n",
      "[19,    20] loss: 0.001\n",
      "[20,    10] loss: 0.001\n",
      "[20,    20] loss: 0.001\n",
      "[21,    10] loss: 0.001\n",
      "[21,    20] loss: 0.001\n",
      "[22,    10] loss: 0.001\n",
      "[22,    20] loss: 0.001\n",
      "[23,    10] loss: 0.001\n",
      "[23,    20] loss: 0.001\n",
      "[24,    10] loss: 0.001\n",
      "[24,    20] loss: 0.001\n",
      "[25,    10] loss: 0.001\n",
      "[25,    20] loss: 0.001\n",
      "[26,    10] loss: 0.001\n",
      "[26,    20] loss: 0.001\n",
      "[27,    10] loss: 0.001\n",
      "[27,    20] loss: 0.001\n",
      "[28,    10] loss: 0.001\n",
      "[28,    20] loss: 0.001\n",
      "[29,    10] loss: 0.001\n",
      "[29,    20] loss: 0.001\n",
      "[30,    10] loss: 0.001\n",
      "[30,    20] loss: 0.001\n",
      "[31,    10] loss: 0.001\n",
      "[31,    20] loss: 0.001\n",
      "[32,    10] loss: 0.001\n",
      "[32,    20] loss: 0.001\n",
      "[33,    10] loss: 0.001\n",
      "[33,    20] loss: 0.001\n",
      "[34,    10] loss: 0.001\n",
      "[34,    20] loss: 0.001\n",
      "[35,    10] loss: 0.001\n",
      "[35,    20] loss: 0.001\n",
      "[36,    10] loss: 0.001\n",
      "[36,    20] loss: 0.001\n",
      "[37,    10] loss: 0.001\n",
      "[37,    20] loss: 0.000\n",
      "[38,    10] loss: 0.001\n",
      "[38,    20] loss: 0.000\n",
      "[39,    10] loss: 0.000\n",
      "[39,    20] loss: 0.000\n",
      "[40,    10] loss: 0.000\n",
      "[40,    20] loss: 0.000\n",
      "[41,    10] loss: 0.000\n",
      "[41,    20] loss: 0.001\n",
      "[42,    10] loss: 0.000\n",
      "[42,    20] loss: 0.000\n",
      "[43,    10] loss: 0.000\n",
      "[43,    20] loss: 0.000\n",
      "[44,    10] loss: 0.000\n",
      "[44,    20] loss: 0.000\n",
      "[45,    10] loss: 0.000\n",
      "[45,    20] loss: 0.000\n",
      "[46,    10] loss: 0.000\n",
      "[46,    20] loss: 0.000\n",
      "[47,    10] loss: 0.000\n",
      "[47,    20] loss: 0.000\n",
      "[48,    10] loss: 0.000\n",
      "[48,    20] loss: 0.000\n",
      "[49,    10] loss: 0.000\n",
      "[49,    20] loss: 0.000\n",
      "[50,    10] loss: 0.000\n",
      "[50,    20] loss: 0.000\n",
      "[51,    10] loss: 0.000\n",
      "[51,    20] loss: 0.000\n",
      "[52,    10] loss: 0.000\n",
      "[52,    20] loss: 0.000\n",
      "[53,    10] loss: 0.000\n",
      "[53,    20] loss: 0.000\n",
      "[54,    10] loss: 0.000\n",
      "[54,    20] loss: 0.000\n",
      "[55,    10] loss: 0.000\n",
      "[55,    20] loss: 0.000\n",
      "[56,    10] loss: 0.000\n",
      "[56,    20] loss: 0.000\n",
      "[57,    10] loss: 0.000\n",
      "[57,    20] loss: 0.000\n",
      "[58,    10] loss: 0.000\n",
      "[58,    20] loss: 0.000\n",
      "[59,    10] loss: 0.000\n",
      "[59,    20] loss: 0.000\n",
      "[60,    10] loss: 0.000\n",
      "[60,    20] loss: 0.000\n",
      "[61,    10] loss: 0.000\n",
      "[61,    20] loss: 0.000\n",
      "[62,    10] loss: 0.000\n",
      "[62,    20] loss: 0.000\n",
      "[63,    10] loss: 0.000\n",
      "[63,    20] loss: 0.000\n",
      "[64,    10] loss: 0.000\n",
      "[64,    20] loss: 0.000\n",
      "[65,    10] loss: 0.000\n",
      "[65,    20] loss: 0.000\n",
      "[66,    10] loss: 0.000\n",
      "[66,    20] loss: 0.000\n",
      "[67,    10] loss: 0.000\n",
      "[67,    20] loss: 0.000\n",
      "[68,    10] loss: 0.000\n",
      "[68,    20] loss: 0.000\n",
      "[69,    10] loss: 0.000\n",
      "[69,    20] loss: 0.000\n",
      "[70,    10] loss: 0.000\n",
      "[70,    20] loss: 0.000\n",
      "[71,    10] loss: 0.000\n",
      "[71,    20] loss: 0.000\n",
      "[72,    10] loss: 0.000\n",
      "[72,    20] loss: 0.000\n",
      "[73,    10] loss: 0.000\n",
      "[73,    20] loss: 0.000\n",
      "[74,    10] loss: 0.000\n",
      "[74,    20] loss: 0.000\n",
      "[75,    10] loss: 0.000\n",
      "[75,    20] loss: 0.000\n",
      "[76,    10] loss: 0.000\n",
      "[76,    20] loss: 0.000\n",
      "[77,    10] loss: 0.000\n",
      "[77,    20] loss: 0.000\n",
      "[78,    10] loss: 0.000\n",
      "[78,    20] loss: 0.000\n",
      "[79,    10] loss: 0.000\n",
      "[79,    20] loss: 0.000\n",
      "[80,    10] loss: 0.000\n",
      "[80,    20] loss: 0.000\n",
      "[81,    10] loss: 0.000\n",
      "[81,    20] loss: 0.000\n",
      "[82,    10] loss: 0.000\n",
      "[82,    20] loss: 0.000\n",
      "[83,    10] loss: 0.000\n",
      "[83,    20] loss: 0.000\n",
      "[84,    10] loss: 0.000\n",
      "[84,    20] loss: 0.000\n",
      "[85,    10] loss: 0.000\n",
      "[85,    20] loss: 0.000\n",
      "[86,    10] loss: 0.000\n",
      "[86,    20] loss: 0.000\n",
      "[87,    10] loss: 0.000\n",
      "[87,    20] loss: 0.000\n",
      "[88,    10] loss: 0.000\n",
      "[88,    20] loss: 0.000\n",
      "[89,    10] loss: 0.000\n",
      "[89,    20] loss: 0.000\n",
      "[90,    10] loss: 0.000\n",
      "[90,    20] loss: 0.000\n",
      "[91,    10] loss: 0.000\n",
      "[91,    20] loss: 0.000\n",
      "[92,    10] loss: 0.000\n",
      "[92,    20] loss: 0.000\n",
      "[93,    10] loss: 0.000\n",
      "[93,    20] loss: 0.000\n",
      "[94,    10] loss: 0.000\n",
      "[94,    20] loss: 0.000\n",
      "[95,    10] loss: 0.000\n",
      "[95,    20] loss: 0.000\n",
      "[96,    10] loss: 0.000\n",
      "[96,    20] loss: 0.000\n",
      "[97,    10] loss: 0.000\n",
      "[97,    20] loss: 0.000\n",
      "[98,    10] loss: 0.000\n",
      "[98,    20] loss: 0.000\n",
      "[99,    10] loss: 0.000\n",
      "[99,    20] loss: 0.000\n",
      "[100,    10] loss: 0.000\n",
      "[100,    20] loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "class TestNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(TestNetwork, self).__init__()\n",
    "\n",
    "        self.input   = nn.Linear(5, 50)     # 5 inputs, 50 outputs\n",
    "        self.hidden1 = nn.Linear(50, 25)    # 50 inputs, 25 outputs\n",
    "        self.hidden2 = nn.Linear(25, 3)     # 25 inputs, 3 outputs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.input(x))\n",
    "        x = nn.functional.relu(self.hidden1(x))\n",
    "        x = self.hidden2(x)\n",
    "        return x\n",
    "    \n",
    "    # Create an instance of the network\n",
    "net = TestNetwork()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(100):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
